---
title: CDC
date: 2021-01-27 16:21:16
categories:
- ipfs
---

### 固定长度切块

使用预先给定的长度来确定分割点，对文件进行分块。假设给定长度为𝑙，文件起始字节编号为0，则将𝑙,2𝑙,…,𝑘𝑙… 字节作为分割点。除了最后一个分块的长度可能小于𝑙，其余分块的长度均等于𝑙。

缺点：
- 无法应对字节移动问题。假设有两个文件$𝐹_1$,$𝐹_2$，其中 $𝐹_2$ 由 $𝐹_1$ 在起始点插入一个字节得到。如果使用固定长度分块的方法，则 $𝐹_2$ 从第2个字节开始，每个字节都是 $𝐹_1$对应字节后移一个字节。因此 $𝐹_2$ 所有的分割点都与文件 $𝐹_1$ 不同。这种情况下，两个文件实际只有一个字节的差别，但是得到的所有分块都不相同，数据去重效果较差。

### 基于hash的CDC （Rabin）


使用Rabin滚动哈希的方法来确定分割点，对文件进行分块。该方法给定一个滑动窗。滑动窗从文件起始字节开始，逐个字节移动。每移动一个字节，计算滑动窗内数据的哈希值$ℎ$。如果哈希值满足预先设定的过滤条件，则将当前窗口位置标记为分割点。例如给定两个整数$𝑟,𝐷$，满足$$ℎ 𝑚𝑜𝑑 𝐷=𝑟$$，则该点可以作为一个分割点。

优点：
- 分割点的确定由文件内容决定，而不是由文件中的偏移量决定。因此在某点插入和删除数据时，不会影响该点后面的分割点的确定，解决了文件分块中字节移动问题。

缺点：
- 窗口每向前滑动一个字节，都要重新计算窗口内数据的哈希值，因此导致算法的计算负载过高，吞吐量较低。

### 基于极值的CDC (AE、RAM)

不使用数据的hash值来确定分割点，而是将字节内容看作数值，使用特定的字节作为分割点。例如AE算法，使用两个窗口，左边是变长窗口，右边是定长窗口，极值字节在两个窗口中间。当极值字节中的内容大于两边的窗口的所有字节的数值，则定长窗口结束点作为分割点。RAM算法则是在搜索开始阶段放置定长窗口，紧接着是一个变长窗口，最后将极值字节放在边界。当极值字节大于定长窗口中的最大值，则作为一个分割点。

优点：
- 基于极值的分块方法避免了逐个字节滚动计算哈希值，而是进行字节内容的大小比较，算法性能有较大提升。基于极值的方法产生的分块长度比基于hash的方法更稳定，出现过长分块的概率较低，有利于提高去重效率。
- 
缺点：
- 基于极值的方法需要在某一窗口内找到最大值，如果插入数据导致窗口内的最大值发生变化，则可能会影响到现有分割点的位置。当分割点位置发生变化，则后续的分块可能发生移位现象。因此基于极值的方法在一定程度上降低了抵抗字节移位的能力，降低了去重效率。

